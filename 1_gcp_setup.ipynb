{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Set Up\n",
    "\n",
    "This notebook goes over how to set up the necessary cloud resources to run the RAG framework. You will be performing the following steps:\n",
    "\n",
    "1. Creating a GCP bucket\n",
    "2. Creating a VertexAI Vector Search Index\n",
    "3. Creating a VertexAI Vector Search endpoint\n",
    "4. Deploying a VertexAI Vector Search endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Install the following modules to run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install google-cloud-aiplatform \\\n",
    "  google-cloud-storage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import storage\n",
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/noabenefraim/qwiklabs_data.git data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable Vertex API and set API Key\n",
    "\n",
    "Before you continue, make sure to refer to the lab instructions to do the follow:\n",
    "\n",
    "1. Enable VertexAI API\n",
    "2. Set a GOOGLE_API_KEY \n",
    "\n",
    "Note, you will use the GOOGLE_API_KEY in the next lab notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"\" #TODO - add your project-id here from the console\n",
    "REGION = \"\"  #TODO - add your region here from the console\n",
    "GCS_BUCKET = \"llamaindex_gcs_bucket\"  # @param {type:\"string\"}\n",
    "VS_INDEX_NAME = \"llamaindex_doc_index\"  # @param {type:\"string\"}\n",
    "VS_INDEX_ENDPOINT_NAME = \"llamaindex_doc_endpoint\"  # @param {type:\"string\"}\n",
    "DOC_FOLDER = \"./data\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bucket_class_location(bucket_name):\n",
    "    \"\"\"\n",
    "    Create a new bucket in the US region with the coldline storage\n",
    "    class.\n",
    "    \"\"\"\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    #Searching for existing GCS bucket\n",
    "    for bucket in storage_client.list_buckets():\n",
    "        if bucket.name==bucket_name:\n",
    "            print(\n",
    "                f\"GCS Bucket {bucket_name} exists already in resource.\"\n",
    "            )\n",
    "            return bucket\n",
    "\n",
    "    #Creating new bucket\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    bucket.storage_class = \"STANDARD\"\n",
    "    new_bucket = storage_client.create_bucket(bucket, location=REGION)\n",
    "\n",
    "    print(\n",
    "        \"Created bucket {} in {} with storage class {}\".format(\n",
    "            new_bucket.name, new_bucket.location, new_bucket.storage_class\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return new_bucket\n",
    "\n",
    "def create_vertex_ai_search_index(index_name, index_dimensions):\n",
    "    \"\"\"\n",
    "    Creates a VertexAI Search Index\n",
    "    NOTE : This operation can take upto 30 minutes\n",
    "    \"\"\"\n",
    "\n",
    "    # check if index exists\n",
    "    index_names = [\n",
    "        index.resource_name\n",
    "        for index in aiplatform.MatchingEngineIndex.list(\n",
    "            filter=f\"display_name={index_name}\"\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    if len(index_names) == 0:\n",
    "        print(f\"Creating Vector Search index {index_name} ...\")\n",
    "        vs_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
    "            display_name=index_name,\n",
    "            dimensions=index_dimensions,\n",
    "            distance_measure_type=\"DOT_PRODUCT_DISTANCE\",\n",
    "            shard_size=\"SHARD_SIZE_SMALL\",\n",
    "            index_update_method=\"STREAM_UPDATE\",  # allowed values BATCH_UPDATE , STREAM_UPDATE,\n",
    "            approximate_neighbors_count = 5\n",
    "        )\n",
    "        print(\n",
    "            f\"Vector Search index {vs_index.display_name} created with resource name {vs_index.resource_name}\"\n",
    "        )\n",
    "    else:\n",
    "        vs_index = aiplatform.MatchingEngineIndex(index_name=index_names[0])\n",
    "        print(\n",
    "            f\"Vector Search index {vs_index.display_name} exists with resource name {vs_index.resource_name}\"\n",
    "        )\n",
    "\n",
    "    return vs_index\n",
    "\n",
    "def create_vertexai_search_endpoint(endpoint_name):\n",
    "    \"\"\"\n",
    "    Creates a VertexAI Search endpoint.\n",
    "    \"\"\"\n",
    "    endpoint_names = [\n",
    "        endpoint.resource_name\n",
    "        for endpoint in aiplatform.MatchingEngineIndexEndpoint.list(\n",
    "            filter=f\"display_name={endpoint_name}\"\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    if len(endpoint_names) == 0:\n",
    "        print(\n",
    "            f\"Creating Vector Search index endpoint {endpoint_name} ...\"\n",
    "        )\n",
    "        vs_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n",
    "            display_name=endpoint_name, public_endpoint_enabled=True\n",
    "        )\n",
    "        print(\n",
    "            f\"Vector Search index endpoint {vs_endpoint.display_name} created with resource name {vs_endpoint.resource_name}\"\n",
    "        )\n",
    "    else:\n",
    "        vs_endpoint = aiplatform.MatchingEngineIndexEndpoint(\n",
    "            index_endpoint_name=endpoint_names[0]\n",
    "        )\n",
    "        print(\n",
    "            f\"Vector Search index endpoint {vs_endpoint.display_name} exists with resource name {vs_endpoint.resource_name}\"\n",
    "        )\n",
    "\n",
    "    return vs_endpoint\n",
    "\n",
    "def deploy_vertexai_search_endpoint(vs_index, vs_endpoint, index_name):\n",
    "    \"\"\"\n",
    "    Deploys a VertexAI search endpoint.\n",
    "    \"\"\"\n",
    "    # check if endpoint exists\n",
    "    index_endpoints = [\n",
    "        (deployed_index.index_endpoint, deployed_index.deployed_index_id)\n",
    "        for deployed_index in vs_index.deployed_indexes\n",
    "    ]\n",
    "\n",
    "    if len(index_endpoints) == 0:\n",
    "        print(\n",
    "            f\"Deploying Vector Search index {vs_index.display_name} at endpoint {vs_endpoint.display_name} ...\"\n",
    "        )\n",
    "        vs_deployed_index = vs_endpoint.deploy_index(\n",
    "            index=vs_index,\n",
    "            deployed_index_id=index_name,\n",
    "            display_name=index_name,\n",
    "            machine_type=\"e2-standard-16\",\n",
    "            min_replica_count=1,\n",
    "            max_replica_count=1,\n",
    "        )\n",
    "        print(\n",
    "            f\"Vector Search index {vs_index.display_name} is deployed at endpoint {vs_deployed_index.display_name}\"\n",
    "        )\n",
    "    else:\n",
    "        vs_deployed_index = aiplatform.MatchingEngineIndexEndpoint(\n",
    "            index_endpoint_name=index_endpoints[0][0]\n",
    "        )\n",
    "        print(\n",
    "            f\"Vector Search index {vs_index.display_name} is already deployed at endpoint {vs_deployed_index.display_name}\"\n",
    "        )\n",
    "\n",
    "    return vs_deployed_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup():\n",
    "    GCS_BUCKET_URI = f\"gs://{GCS_BUCKET}\"\n",
    "\n",
    "    # The number of dimensions for the gecko text embeddings is 768\n",
    "    VS_DIMENSIONS = 768\n",
    "    # Vertex AI Vector Search Index configuration\n",
    "\n",
    "    aiplatform.init(project=PROJECT_ID, location=REGION)\n",
    "\n",
    "    new_bucket = create_bucket_class_location(GCS_BUCKET)\n",
    "    vs_index = create_vertex_ai_search_index(VS_INDEX_NAME, VS_DIMENSIONS)\n",
    "    vs_endpoint = create_vertexai_search_endpoint(VS_INDEX_ENDPOINT_NAME)\n",
    "    vs_deployed_index = deploy_vertexai_search_endpoint(vs_index, vs_endpoint, VS_INDEX_NAME)\n",
    "\n",
    "    return new_bucket, vs_index, vs_endpoint, vs_deployed_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step can take ~30 minutes to set up the necessary resources.\n",
    "bucket,vs_index, vs_endpoint, deployed_endpoint = setup()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! Set up is complete. \n",
    "\n",
    "Run the cell below to capture the IDs of the resources that we will use in the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Index ID: \" + vs_index.name)\n",
    "print(\"Endpoint ID: \" + vs_endpoint.name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
